{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a map of Countries with current travel restrictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from dateutil.parser import parse\n",
    "import config as cfg\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define and get the website (estonian version)**\n",
    "\n",
    "We are using [requests](https://requests.readthedocs.io/en/master/) to download the webpage, and the [BeautifulSoup](https://www.crummy.com/software/BeautifulSoup/bs4/doc/) package to parse the source code of the webpage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = r'https://vm.ee/et/teave-riikide-ja-liikumispiirangute-kohta-eestisse-saabujatele'\n",
    "\n",
    "r = requests.get(url)\n",
    "soup = BeautifulSoup(r.text, features=\"html.parser\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Regex to find dates and current timeframe**\n",
    "\n",
    "The data on the website is subject to change. The format can change with a new update, so the information we are looking for might be in a different position, or it has to be extracted from text. Right now, the website stores the last-update information on and the valid time frame in the text, in the format of: \n",
    "\n",
    "```DD.MM-DD.MM.YYYY (seisuga DD.MM.YYYY)```\n",
    "\n",
    "The text might change at some point, but for now we can use regular expressions to extract the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the too regular expressions we need. The first one extracts the time the data has been released/updated. The second contains the time interval of validity. Regular expression have been drafted on [RegExr](https://regexr.com/). Note, that as soon the text changes on the webite, the regular expression might need to be updated. They are somewhat dynamic (leading 0), but not entirely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling to search for \"seisuga DD.MM.YYYY\"\n",
    "p1 = re.compile(r'seisuga\\s+((?:[0]?[1-9]|[1|2][0-9]|[3][0|1])[.](?:[0]?[1-9]|[1][0-2])[.](?:[0-9]{4}|[0-9]{2}))?')\n",
    "\n",
    "# Compiling to search for \"DD.MM-DD.MM.YYYY\"\n",
    "p2 = re.compile(r'((?:[0]?[1-9]|[1|2][0-9]|[3][0|1])[.](?:[0]?[1-9]|[1][0-2])[.]?(?:[0-9]{4}|[0-9]{2})?)-\\s*((?:[0]?[1-9]|[1|2][0-9]|[3][0|1])[.](?:[0]?[1-9]|[1][0-2])[.](?:[0-9]{4}|[0-9]{2}))?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding and parsing the Dates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The website has been updated on 11.09.2020, the current values are valid from 14.09.2020 to 20.09.2020.\n"
     ]
    }
   ],
   "source": [
    "# Day of release (last update)\n",
    "up_date = datetime.datetime.strptime(p1.findall(li)[0], '%d.%m.%Y')\n",
    "\n",
    "# Validity period\n",
    "li = soup.find(text=p1)\n",
    "valid_from = parse(p2.findall(li)[0][0])\n",
    "valid_to = parse(p2.findall(li)[0][1])\n",
    "\n",
    "# Print to check if it has been extracted properly\n",
    "print(\"The website has been updated on {}, the current values are valid from {} to {}.\".format(up_date.strftime('%d.%m.%Y'), \n",
    "                                                                                             valid_from.strftime('%d.%m.%Y'),\n",
    "                                                                                             valid_to.strftime('%d.%m.%Y')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding countries in the text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the config.py file in the same folder a dictionary has been created containing all the countries, their English and Estonian translation, matched together by their 2-digit Country code. ([en](https://en.wikipedia.org/wiki/ISO_3166-1), [ee](https://et.wikipedia.org/wiki/ISO_maakoodide_loend))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The file can be imported as a package, and the containing dictionary is assigned to a variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AF': {'ee': 'Afganistan', 'en': 'Afghanistan'},\n",
       " 'AX': {'ee': 'Ahvenamaa', 'en': 'Åland Islands'},\n",
       " 'AL': {'ee': 'Albaania', 'en': 'Albania'},\n",
       " 'DZ': {'ee': 'Alžeeria', 'en': 'Algeria'},\n",
       " 'AS': {'ee': 'Ameerika Samoa', 'en': 'American Samoa'}}"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import config as cfg\n",
    "a2_dct = cfg.a2_dct\n",
    "\n",
    "dict(list(a2_dct.items())[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Itaalia 27'"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = ul1.find(text=re.compile( 'Itaalia' + '\\s*[\\d]{1,3}([,]\\d)?'))\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the section containing EU-countries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The webpage has different sections, which are all subject to change. The sections are defined by [```<ul>```-tags](https://www.w3schools.com/tags/tag_ul.asp) (unordered lists), containing [```<li>```-items](https://www.w3schools.com/tags/tag_li.asp) (list items). We can use BeautifulSoup to find the unordered lists in the website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 33 unordered lists defined in the website, in total they contain 232 list items.\n"
     ]
    }
   ],
   "source": [
    "uls = soup.find_all('ul')\n",
    "ils = soup.find_all('li')\n",
    "print(\"There are {} unordered lists defined in the website, in total they contain {} list items.\".format(len(uls),len(ils)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this stage a bit of manual data exploration is advised. We need to find the unordered list, which contains the data we are looking for (list of EU-countries and their respective active cases / 100k inhabitants). This can certainly be automized, but as long it doesn't change permanently, it is easier to just select the right list. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ul>\n",
       "<li><span class=\"node-text-color-red\"><strong>Andorra 266,5</strong></span></li>\n",
       "<li><span class=\"node-text-color-red\"><strong>Austria 59,7</strong></span></li>\n",
       "<li><span class=\"node-text-color-red\"><strong>Belgia 47,1</strong></span></li>\n",
       "<li><span class=\"node-text-color-red\"><strong>Bulgaaria 24,1</strong></span></li>\n",
       "<li><span class=\"node-text-color-red\"><strong>Hispaania 265,5</strong></span></li>\n",
       "<li><span class=\"node-text-color-red\"><strong>Holland 57,2</strong></span></li>\n",
       "<li><span class=\"node-text-color-red\"><strong>Horvaatia 91,4</strong></span></li>\n",
       "<li><span class=\"node-text-color-red\"><strong>Iirimaa 38,9</strong></span></li>\n",
       "<li>\n",
       "<p><span class=\"node-text-color-red\"><strong>Island 19,6</strong></span></p>\n",
       "</li>\n",
       "<li><span class=\"node-text-color-red\"><strong>Itaalia 31,9</strong></span></li>\n",
       "<li><span class=\"node-text-color-red\"><strong>Kreeka 27,2</strong></span></li>\n",
       "<li><strong>Küpros 4,1</strong></li>\n",
       "<li><strong>Leedu 15,6</strong></li>\n",
       "<li><strong>Liechtenstein 7,8</strong></li>\n",
       "<li><span class=\"node-text-color-red\"><strong>Luksemburg 88,8</strong></span></li>\n",
       "<li><strong>Läti 4,3</strong></li>\n",
       "<li><span class=\"node-text-color-red\"><strong>Malta 68,9</strong></span></li>\n",
       "<li><strong><span class=\"node-text-color-red\">Monaco 124</span></strong></li>\n",
       "<li><span class=\"node-text-color-red\"><strong>Norra 23,3</strong></span></li>\n",
       "<li><strong style=\"color: rgb(189, 73, 50);\">Poola 20,5</strong></li>\n",
       "<li><span class=\"node-text-color-red\"><strong>Portugal 53,1</strong></span></li>\n",
       "<li><span class=\"node-text-color-red\"><strong>Prantsusmaa 140,6</strong></span></li>\n",
       "<li><span class=\"node-text-color-red\"><strong>Rootsi 22,7</strong></span></li>\n",
       "<li><span class=\"node-text-color-red\"><strong>Rumeenia 85,2</strong></span></li>\n",
       "<li><span class=\"node-text-color-red\"><strong>Saksamaa 20,9</strong></span></li>\n",
       "<li><span class=\"node-text-color-red\"><strong>San Marino 72,6</strong></span></li>\n",
       "<li><span class=\"node-text-color-red\"><strong>Slovakkia 25,6</strong></span></li>\n",
       "<li><span class=\"node-text-color-red\"><strong>Sloveenia 30,4</strong></span></li>\n",
       "<li><strong>Soome 8,2</strong></li>\n",
       "<li><span class=\"node-text-color-red\"><strong>Šveits 55,0</strong></span></li>\n",
       "<li><span class=\"node-text-color-red\"><strong>Taani 39,6</strong></span></li>\n",
       "<li><span class=\"node-text-color-red\"><strong>Tšehhi 85,6</strong></span></li>\n",
       "<li><span class=\"node-text-color-red\"><strong>Ungari 49,2</strong></span></li>\n",
       "<li><strong>Vatikan 0,0</strong></li>\n",
       "<li><strong><span class=\"node-text-color-red\">Ühendkuningriik 41,7</span></strong></li>\n",
       "</ul>"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The list we are after is currently the 20 list out of 33.\n",
    "ul1 = soup.find_all('ul')[20]\n",
    "ul1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the printed section we can find all the data we are looking for. Unfortunately the formatting is not homogeneous, which will make extraction a bit more tedious. There are different ```<span>``` classes, and various use cases of the ```<strong>``` tag, which indicate whether the 2-week quarantine rule applies or not. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we are going to loop through all the countries, we are testing our detection. The following command is used to find the country and the number. Note, that the regular expression contains the option for several spaces ```\\s*``` (sometimes there is more than one), and the option for decimal number or not ```([,]\\d)?```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Prantsusmaa 140,6'"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p1 = re.compile( 'Prantsusmaa' + '\\s*[\\d]{1,3}([,]\\d)?')\n",
    "res = ul1.find(text=p1)\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next step we want to extract the decimal value. At the same time we can look for a present asterisk, highlighting that there is a special treatment for this case. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('140,6', '')"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p2 = re.compile(r'(\\d*\\,?\\d+)(\\*)?')\n",
    "res2 = p2.findall(res)[0]\n",
    "res2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case the country is highlighted in<font color=red> **bold and red ** </font> returning from the country implies a 14 day quarantine period. Whether or not the formatting exists can be checked like this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "if res.find_parent('span', {'class': 'node-text-color-red'}):\n",
    "    print(True)\n",
    "    \n",
    "# or \n",
    "if res.find_parent('strong', {'style' : 'color: rgb(189, 73, 50);'}):\n",
    "    print(True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Andorra 266,5 266.5####\n",
      "Austria 59,7 59.7####\n",
      "Belgia 47,1 47.1####\n",
      "Bulgaaria 24,1 24.1####\n",
      "Hispaania 265,5 265.5####\n",
      "Holland 57,2 57.2####\n",
      "Horvaatia 91,4 91.4####\n",
      "Iirimaa 38,9 38.9####\n",
      "Island 19,6 19.6####\n",
      "Itaalia 31,9 31.9####\n",
      "Kreeka 27,2 27.2####\n",
      "Küpros 4,1 4.1\n",
      "Leedu 15,6 15.6\n",
      "Liechtenstein 7,8 7.8\n",
      "Luksemburg 88,8 88.8####\n",
      "Läti 4,3 4.3\n",
      "Malta 68,9 68.9####\n",
      "Monaco 124 124.0####\n",
      "Norra 23,3 23.3####\n",
      "Poola 20,5 20.5####\n",
      "Portugal 53,1 53.1####\n",
      "Prantsusmaa 140,6 140.6####\n",
      "Rootsi 22,7 22.7####\n",
      "Rumeenia 85,2 85.2####\n",
      "Saksamaa 20,9 20.9####\n",
      "San Marino 72,6 72.6####\n",
      "Slovakkia 25,6 25.6####\n",
      "Sloveenia 30,4 30.4####\n",
      "Soome 8,2 8.2\n",
      "Šveits 55,0 55.0####\n",
      "Taani 39,6 39.6####\n",
      "Tšehhi 85,6 85.6####\n",
      "Ungari 49,2 49.2####\n",
      "Vatikan 0,0 0.0\n",
      "Ühendkuningriik 41,7 41.7####\n"
     ]
    }
   ],
   "source": [
    "# Creating dictionaries and lists where the collected information is stored\n",
    "a2_status = {}  # \n",
    "found_countries = [] # countries that were found on the webpage\n",
    "quarantine = [] # countries needing quarantine on re-entry\n",
    "no_quarantine = [] # countries without quarantine rule\n",
    "\n",
    "for a2 in a2_dct.keys(): # looping through all country codes\n",
    "    cntry = a2_dct[a2]['ee'] # get the estonian translation\n",
    "    cntry_en = a2_dct[a2]['en'] # get the english translation\n",
    "    # find the country in the selected unordered list\n",
    "    res = ul1.find(text=p1) # for p1 see above\n",
    "    \n",
    "    if res: # if it is found\n",
    "        found_countries.append(cntry_en) # append it to the list of countries found\n",
    "        res2 = p2.findall(res)[0] # search for the value (see above)\n",
    "        val = float(res2[0].replace(',','.')) # convert value from string decimal (komma) to float\n",
    "        a2_status[a2] = {'val': val} # assign it to the dictionary\n",
    "        \n",
    "        # the following is checking whether a asterisk is present \n",
    "        try:\n",
    "            note = res2[0][1]\n",
    "        except:\n",
    "            note = ''\n",
    "        if note == '':\n",
    "            a2_status[a2]['note'] = False # assign to the dictionary\n",
    "        else:\n",
    "            a2_status[a2]['note'] = True\n",
    "            \n",
    "        print(res, val, end = '')\n",
    "        \n",
    "        # check whether quarantine rules apply or not\n",
    "        if res.find_parent('span', {'class': 'node-text-color-red'}) or res.find_parent('strong', {'style' : 'color: rgb(189, 73, 50);'}):\n",
    "            print('####')\n",
    "            a2_status[a2]['fom'] = False # assign to the dictionary\n",
    "            quarantine.append(cntry_en) # add to the list of countries that need to quarantine\n",
    "        else:\n",
    "            print('')\n",
    "            a2_status[a2]['fom'] = True\n",
    "            no_quarantine.append(cntry_en) # add to the list of countries that do not need to quarantine\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Austraalia\n",
      "Gruusia\n",
      "Jaapan\n",
      "Kanada\n",
      "Lõuna-Korea\n",
      "Rwanda\n",
      "Tai\n",
      "Tuneesia\n",
      "Uruguay\n",
      "Uus-Meremaa\n",
      "Found countries: 45\n",
      "['Andorra', 'Austria', 'Belgium', 'Bulgaria', 'Spain', 'Netherlands', 'Croatia', 'Ireland', 'Iceland', 'Italy', 'Greece', 'Cyprus', 'Lithuania', 'Liechtenstein', 'Luxembourg', 'Latvia', 'Malta', 'Monaco', 'Norway', 'Poland', 'Portugal', 'France', 'Sweden', 'Romania', 'Germany', 'San Marino', 'Slovakia', 'Slovenia', 'Finland', 'Switzerland', 'Denmark', 'Czechia', 'Hungary', 'Holy See', 'United Kingdom', 'Australia', 'Georgia', 'Japan', 'Canada', 'Korea, Republic of', 'Rwanda', 'Thailand', 'Tunisia', 'Uruguay', 'New Zealand']\n",
      "Countries that need quarantine: 29\n",
      "['Andorra', 'Austria', 'Belgium', 'Bulgaria', 'Spain', 'Netherlands', 'Croatia', 'Ireland', 'Iceland', 'Italy', 'Greece', 'Luxembourg', 'Malta', 'Monaco', 'Norway', 'Poland', 'Portugal', 'France', 'Sweden', 'Romania', 'Germany', 'San Marino', 'Slovakia', 'Slovenia', 'Switzerland', 'Denmark', 'Czechia', 'Hungary', 'United Kingdom']\n",
      "Countries that need NO quarantine: 16\n",
      "['Cyprus', 'Lithuania', 'Liechtenstein', 'Latvia', 'Finland', 'Holy See', 'Australia', 'Georgia', 'Japan', 'Canada', 'Korea, Republic of', 'Rwanda', 'Thailand', 'Tunisia', 'Uruguay', 'New Zealand']\n"
     ]
    }
   ],
   "source": [
    "        \n",
    "ul2 = soup.find_all('ul')[21]\n",
    "for a2 in a2_dct.keys():\n",
    "    cntry = a2_dct[a2]['ee']\n",
    "    cntry_en = a2_dct[a2]['en']\n",
    "    res = ul2.find(text=re.compile('(' + cntry + ')'))\n",
    "    if res:\n",
    "        a2_status[a2] = {'val': None}\n",
    "        print(res, end = '')\n",
    "        found_countries.append(cntry_en)\n",
    "        if res.find_parent('strong'):\n",
    "            print('####')\n",
    "            a2_status[a2]['fom'] = False\n",
    "            quarantine.append(cntry_en)\n",
    "        else:\n",
    "            print('')\n",
    "            a2_status[a2]['fom'] = True\n",
    "            no_quarantine.append(cntry_en)\n",
    "        \n",
    "        p = re.compile('([\\*])')\n",
    "        res2 = p.findall(res)\n",
    "        if note == '':\n",
    "            a2_status[a2]['note'] = False\n",
    "        else:\n",
    "            a2_status[a2]['note'] = True\n",
    "            \n",
    "print('Found countries: {}'.format(len(found_countries)))\n",
    "print(found_countries)\n",
    "print('Countries that need quarantine: {}'.format(len(quarantine)))\n",
    "print(quarantine)\n",
    "print('Countries that need NO quarantine: {}'.format(len(no_quarantine)))\n",
    "print(no_quarantine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AD': {'val': 266.5, 'note': True, 'fom': False},\n",
       " 'AT': {'val': 59.7, 'note': True, 'fom': False},\n",
       " 'BE': {'val': 47.1, 'note': True, 'fom': False},\n",
       " 'BG': {'val': 24.1, 'note': True, 'fom': False},\n",
       " 'ES': {'val': 265.5, 'note': True, 'fom': False},\n",
       " 'NL': {'val': 57.2, 'note': True, 'fom': False},\n",
       " 'HR': {'val': 91.4, 'note': True, 'fom': False},\n",
       " 'IE': {'val': 38.9, 'note': True, 'fom': False},\n",
       " 'IS': {'val': 19.6, 'note': True, 'fom': False},\n",
       " 'IT': {'val': 31.9, 'note': True, 'fom': False},\n",
       " 'GR': {'val': 27.2, 'note': True, 'fom': False},\n",
       " 'CY': {'val': 4.1, 'note': True, 'fom': True},\n",
       " 'LT': {'val': 15.6, 'note': True, 'fom': True},\n",
       " 'LI': {'val': 7.8, 'note': True, 'fom': True},\n",
       " 'LU': {'val': 88.8, 'note': True, 'fom': False},\n",
       " 'LV': {'val': 4.3, 'note': True, 'fom': True},\n",
       " 'MT': {'val': 68.9, 'note': True, 'fom': False},\n",
       " 'MC': {'val': 124.0, 'note': True, 'fom': False},\n",
       " 'NO': {'val': 23.3, 'note': True, 'fom': False},\n",
       " 'PL': {'val': 20.5, 'note': True, 'fom': False},\n",
       " 'PT': {'val': 53.1, 'note': True, 'fom': False},\n",
       " 'FR': {'val': 140.6, 'note': True, 'fom': False},\n",
       " 'SE': {'val': 22.7, 'note': True, 'fom': False},\n",
       " 'RO': {'val': 85.2, 'note': True, 'fom': False},\n",
       " 'DE': {'val': 20.9, 'note': True, 'fom': False},\n",
       " 'SM': {'val': 72.6, 'note': True, 'fom': False},\n",
       " 'SK': {'val': 25.6, 'note': True, 'fom': False},\n",
       " 'SI': {'val': 30.4, 'note': True, 'fom': False},\n",
       " 'FI': {'val': 8.2, 'note': True, 'fom': True},\n",
       " 'CH': {'val': 55.0, 'note': True, 'fom': False},\n",
       " 'DK': {'val': 39.6, 'note': True, 'fom': False},\n",
       " 'CZ': {'val': 85.6, 'note': True, 'fom': False},\n",
       " 'HU': {'val': 49.2, 'note': True, 'fom': False},\n",
       " 'VA': {'val': 0.0, 'note': True, 'fom': True},\n",
       " 'UK': {'val': 41.7, 'note': True, 'fom': False},\n",
       " 'AU': {'val': None, 'fom': True, 'note': True},\n",
       " 'GE': {'val': None, 'fom': True, 'note': True},\n",
       " 'JP': {'val': None, 'fom': True, 'note': True},\n",
       " 'CA': {'val': None, 'fom': True, 'note': True},\n",
       " 'KR': {'val': None, 'fom': True, 'note': True},\n",
       " 'RW': {'val': None, 'fom': True, 'note': True},\n",
       " 'TH': {'val': None, 'fom': True, 'note': True},\n",
       " 'TN': {'val': None, 'fom': True, 'note': True},\n",
       " 'UY': {'val': None, 'fom': True, 'note': True},\n",
       " 'NZ': {'val': None, 'fom': True, 'note': True}}"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a2_status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AD': {'val': 266.5, 'note': True, 'fom': False},\n",
       " 'AT': {'val': 59.7, 'note': True, 'fom': False},\n",
       " 'BE': {'val': 47.1, 'note': True, 'fom': False},\n",
       " 'BG': {'val': 24.1, 'note': True, 'fom': False},\n",
       " 'ES': {'val': 265.5, 'note': True, 'fom': False},\n",
       " 'NL': {'val': 57.2, 'note': True, 'fom': False},\n",
       " 'HR': {'val': 91.4, 'note': True, 'fom': False},\n",
       " 'IE': {'val': 38.9, 'note': True, 'fom': False},\n",
       " 'IS': {'val': 19.6, 'note': True, 'fom': False},\n",
       " 'IT': {'val': 31.9, 'note': True, 'fom': False},\n",
       " 'GR': {'val': 27.2, 'note': True, 'fom': False},\n",
       " 'CY': {'val': 4.1, 'note': True, 'fom': True},\n",
       " 'LT': {'val': 15.6, 'note': True, 'fom': True},\n",
       " 'LI': {'val': 7.8, 'note': True, 'fom': True},\n",
       " 'LU': {'val': 88.8, 'note': True, 'fom': False},\n",
       " 'LV': {'val': 4.3, 'note': True, 'fom': True},\n",
       " 'MT': {'val': 68.9, 'note': True, 'fom': False},\n",
       " 'MC': {'val': 124.0, 'note': True, 'fom': False},\n",
       " 'NO': {'val': 23.3, 'note': True, 'fom': False},\n",
       " 'PL': {'val': 20.5, 'note': True, 'fom': False},\n",
       " 'PT': {'val': 53.1, 'note': True, 'fom': False},\n",
       " 'FR': {'val': 140.6, 'note': True, 'fom': False},\n",
       " 'SE': {'val': 22.7, 'note': True, 'fom': False},\n",
       " 'RO': {'val': 85.2, 'note': True, 'fom': False},\n",
       " 'DE': {'val': 20.9, 'note': True, 'fom': False},\n",
       " 'SM': {'val': 72.6, 'note': True, 'fom': False},\n",
       " 'SK': {'val': 25.6, 'note': True, 'fom': False},\n",
       " 'SI': {'val': 30.4, 'note': True, 'fom': False},\n",
       " 'FI': {'val': 8.2, 'note': True, 'fom': True},\n",
       " 'CH': {'val': 55.0, 'note': True, 'fom': False},\n",
       " 'DK': {'val': 39.6, 'note': True, 'fom': False},\n",
       " 'CZ': {'val': 85.6, 'note': True, 'fom': False},\n",
       " 'HU': {'val': 49.2, 'note': True, 'fom': False},\n",
       " 'VA': {'val': 0.0, 'note': True, 'fom': True},\n",
       " 'UK': {'val': 41.7, 'note': True, 'fom': False},\n",
       " 'AU': {'val': None, 'fom': True, 'note': True},\n",
       " 'GE': {'val': None, 'fom': True, 'note': True},\n",
       " 'JP': {'val': None, 'fom': True, 'note': True},\n",
       " 'CA': {'val': None, 'fom': True, 'note': True},\n",
       " 'KR': {'val': None, 'fom': True, 'note': True},\n",
       " 'RW': {'val': None, 'fom': True, 'note': True},\n",
       " 'TH': {'val': None, 'fom': True, 'note': True},\n",
       " 'TN': {'val': None, 'fom': True, 'note': True},\n",
       " 'UY': {'val': None, 'fom': True, 'note': True},\n",
       " 'NZ': {'val': None, 'fom': True, 'note': True},\n",
       " 'GB': {'val': 41.7, 'note': True, 'fom': False},\n",
       " 'EE': {'val': None, 'note': False, 'fom': True}}"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a2_status['GB'] = a2_status['UK']\n",
    "a2_status['EE'] = {'val': None, 'note': False, 'fom': True}\n",
    "a2_status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "from arcgis.gis import GIS\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "gis = GIS(profile=\"COVDemo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fom_lu = {True: 1, False: 2}\n",
    "fom_lu[True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_id = r'abe1b723785f4ecfbb602697d50872a0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytz\n",
    "from dateutil.tz import tzlocal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2020, 9, 11, 0, 0)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AS, AS UM, UM UM UM UM UM UM CK, CK PF, PF UM, UM UM UM UM UM UM UM, UM UM UM UM UM UM NU, NU PN, PN WS, WS TK, TK TO, TO WF, WF UM, UM UM UM UM UM UM UM, UM UM UM UM UM UM SV, SV GT, GT MX, MX CA, CA found\n",
      "AR, AR FK, FK CL, CL EC, EC PE, PE BO, BO BR, BR PY, PY UY, UY found\n",
      "GS, GS AQ, AQ FJ, FJ SH, SH AI, AI AG, AG AW, AW BS, BS BB, BB BZ, BZ BM, BM BQ, BQ BQ BQ VG, VG KY, KY CO, CO CR, CR CU, CU CW, CW DM, DM DO, DO GF, GF GD, GD GP, GP GY, GY HT, HT HN, HN JM, JM MQ, MQ MS, MS NI, NI PA, PA PR, PR BQ, BQ BQ BQ BL, BL BQ, BQ BQ BQ KN, KN LC, LC MF, MF PM, PM VC, VC SX, SX SR, SR TT, TT TC, TC VI, VI VE, VE BF, BF CV, CV CI, CI GM, GM GH, GH GI, GI GN, GN GW, GW LR, LR ML, ML MR, MR MA, MA PT, PT found\n",
      "SN, SN SL, SL GL, GL GG, GG IE, IE found\n",
      "IM, IM JE, JE GB, GB found\n",
      "IS, IS found\n",
      "FO, FO SJ, SJ SJ BV, BV NZ, NZ found\n",
      "AO, AO BW, BW BI, BI KM, KM CG, CG CD, CD GA, GA KE, KE LS, LS MW, MW TF, TF TF TF MZ, MZ NA, NA RW, RW found\n",
      "ST, ST ZA, ZA SZ, SZ TZ, TZ ZM, ZM ZW, ZW IO, IO TF, TF TF TF HM, HM MG, MG MU, MU YT, YT TF, TF TF TF RE, RE SC, SC DZ, DZ BJ, BJ CM, CM CF, CF TD, TD GQ, GQ KI, KI LY, LY MT, MT found\n",
      "NE, NE NG, NG TG, TG TN, TN found\n",
      "CY, CY found\n",
      "DJ, DJ EG, EG ER, ER ET, ET GR, GR found\n",
      "IQ, IQ IL, IL JO, JO LB, LB PS, PS SS, SS SD, SD SY, SY TR, TR UG, UG AD, AD found\n",
      "US, US FR, FR found\n",
      "LI, LI found\n",
      "MC, MC found\n",
      "CH, CH found\n",
      "BE, BE found\n",
      "DE, DE found\n",
      "LU, LU found\n",
      "NL, NL found\n",
      "AL, AL AT, AT found\n",
      "BA, BA HR, HR found\n",
      "CZ, CZ found\n",
      "DK, DK found\n",
      "HU, HU found\n",
      "IT, IT found\n",
      "ME, ME PL, PL found\n",
      "SM, SM found\n",
      "RS, RS SK, SK found\n",
      "SI, SI found\n",
      "MK, MK VA, VA found\n",
      "NO, NO found\n",
      "SJ, SJ SJ SE, SE found\n",
      "BY, BY BG, BG found\n",
      "EE, EE found\n",
      "FI, FI found\n",
      "GE, GE found\n",
      "LV, LV found\n",
      "LT, LT found\n",
      "MD, MD RO, RO found\n",
      "UA, UA AF, AF BH, BH IN, IN IR, IR KW, KW MV, MV NP, NP OM, OM PK, PK QA, QA SA, SA SO, SO LK, LK TJ, TJ TM, TM AE, AE YE, YE AM, AM AZ, AZ KZ, KZ KG, KG UZ, UZ CX, CX CC, CC ID, ID TL, TL AU, AU found\n",
      "NR, NR NC, NC NF, NF PG, PG SB, SB TV, TV VU, VU KH, KH LA, LA MY, MY MM, MM SG, SG TH, TH found\n",
      "VN, VN BD, BD BT, BT CN, CN BN, BN PH, PH KR, KR found\n",
      "MN, MN KP, KP GU, GU JP, JP found\n",
      "MH, MH FM, FM MP, MP PW, PW UM, UM UM UM UM UM UM RU, RU RU RU, RU RU ES, ES found\n",
      "ES found\n",
      "ES, ES found\n",
      "ES found\n",
      "\n"
     ]
    }
   ],
   "source": [
    "regq = gis.content.get(current_id)\n",
    "regions_flayer = regq.layers[0]\n",
    "regions_fset = regions_flayer.query()\n",
    "sdf = regions_fset.sdf\n",
    "all_features = regions_fset.features\n",
    "\n",
    "features_to_update = []\n",
    "#a2_status = {}\n",
    "\n",
    "if len(a2_status) == 0 or pd.isnull(sdf.lastUpdate.max()) or date.astimezone(pytz.utc) > sdf.lastUpdate.max().replace(tzinfo=pytz.utc):\n",
    "    for a2 in sdf.ISO_2DIGIT.values:\n",
    "        print(a2, end=', ')\n",
    "        original_features = [f for f in all_features if f.attributes['ISO_2DIGIT'] == a2] # query the layer\n",
    "        for original_feature in original_features:\n",
    "            feature_to_be_updated = deepcopy(original_feature) # copy the original thing\n",
    "            del feature_to_be_updated.attributes['SHAPE']\n",
    "            print(a2, end = ' ')\n",
    "            if a2 in a2_status:\n",
    "                print('found')\n",
    "                curVal = a2_status[a2]['val']\n",
    "                prevVal = feature_to_be_updated.attributes['activeCasesp100k']\n",
    "                feature_to_be_updated.attributes['activeCasesp100k'] = curVal\n",
    "                feature_to_be_updated.attributes['prevActiveCp100k'] = prevVal\n",
    "                feature_to_be_updated.attributes['addInfo'] = int(a2_status[a2]['note'])\n",
    "                feature_to_be_updated.attributes['StatusCode'] = fom_lu[a2_status[a2]['fom']]\n",
    "                feature_to_be_updated.attributes['prevUpdate'] = feature_to_be_updated.attributes['lastUpdate']\n",
    "                feature_to_be_updated.attributes['lastUpdate'] = date\n",
    "                feature_to_be_updated.attributes['validFrom'] = valid_from\n",
    "                feature_to_be_updated.attributes['validTo'] = valid_to\n",
    "                if prevVal and curVal:\n",
    "                    feature_to_be_updated.attributes['activeCasesTrend'] = 2 if round(prevVal,1) > round(curVal,1) else 0\n",
    "                    feature_to_be_updated.attributes['activeCasesTrend'] = 1 if round(prevVal,1) < round(curVal,1) else 0\n",
    "                else:\n",
    "                    feature_to_be_updated.attributes['activeCasesTrend'] = 0\n",
    "            else:\n",
    "                feature_to_be_updated.attributes['activeCasesp100k'] = None\n",
    "                feature_to_be_updated.attributes['prevActiveCp100k'] = None\n",
    "                feature_to_be_updated.attributes['addInfo'] = None\n",
    "                feature_to_be_updated.attributes['StatusCode'] = 9\n",
    "                feature_to_be_updated.attributes['prevUpdate'] = None\n",
    "                feature_to_be_updated.attributes['lastUpdate'] = None\n",
    "                feature_to_be_updated.attributes['validFrom'] = None\n",
    "                feature_to_be_updated.attributes['validTo'] = None\n",
    "                feature_to_be_updated.attributes['activeCasesTrend'] = 0\n",
    "            feature_to_be_updated2 = {}\n",
    "            feature_to_be_updated2['attributes'] = feature_to_be_updated.attributes\n",
    "            features_to_update.append(feature_to_be_updated2)\n",
    "    print('')\n",
    "    update_result = regions_flayer.edit_features(updates=features_to_update)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_update"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
